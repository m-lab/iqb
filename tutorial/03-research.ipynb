{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bec80ef",
   "metadata": {},
   "source": [
    "# Research\n",
    "\n",
    "I am now showing you how a researcher can interact with\n",
    "the local or remote cache w/o using BigQuery.\n",
    "\n",
    "Here we use the higher-level `IQBCache` API, which intentionally has no\n",
    "BigQuery toggle and focuses on reading cached data.\n",
    "\n",
    "We are pointing to the same cache directory that the pipeline writes to,\n",
    "but the cache component itself is read-only.\n",
    "\n",
    "The source code for `IQBCache` lives inside `./library/src/iqb/cache`.\n",
    "\n",
    "As a starting point, let's instantiate the cache with:\n",
    "\n",
    "1. a directory where to cache the query results\n",
    "\n",
    "2. the optional remote cache instance.\n",
    "\n",
    "We use the same dataset naming conventions described in the queries chapter, so\n",
    "the cache paths line up with the query templates and granularities.\n",
    "\n",
    "The remote cache assumes the existence of a manifest file describing\n",
    "what remote files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652618c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iqb import IQBCache, IQBGitHubRemoteCache\n",
    "\n",
    "cache = IQBCache(\n",
    "    data_dir=\"03-research.dir\",\n",
    "    remote_cache=IQBGitHubRemoteCache(\n",
    "        data_dir=\"03-research.dir\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918354e",
   "metadata": {},
   "source": [
    "As before, we are using a manifest, let's print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7dea59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"files\": {\n",
      "        \"cache/v1/20251001T000000Z/20251101T000000Z/downloads_by_country/data.parquet\": {\n",
      "            \"sha256\": \"82226cc007001bd5545d5b1f036eefe1707c43608581cc5c06e5f055867be376\",\n",
      "            \"url\": \"https://github.com/m-lab/iqb/releases/download/v0.2.0/82226cc00700__cache__v1__20251001T000000Z__20251101T000000Z__downloads_by_country__data.parquet\"\n",
      "        },\n",
      "        \"cache/v1/20251001T000000Z/20251101T000000Z/downloads_by_country/stats.json\": {\n",
      "            \"sha256\": \"975ce9997ec33aad693b4367289b130a0ff0258f94d8c904bd8942debc190c3f\",\n",
      "            \"url\": \"https://github.com/m-lab/iqb/releases/download/v0.2.0/975ce9997ec3__cache__v1__20251001T000000Z__20251101T000000Z__downloads_by_country__stats.json\"\n",
      "        },\n",
      "        \"cache/v1/20251001T000000Z/20251101T000000Z/uploads_by_country/data.parquet\": {\n",
      "            \"sha256\": \"c1f384988a07859d42d34d332806de6d8ce576a26d9d42fce6b4c90628b8be90\",\n",
      "            \"url\": \"https://github.com/m-lab/iqb/releases/download/v0.2.0/c1f384988a07__cache__v1__20251001T000000Z__20251101T000000Z__uploads_by_country__data.parquet\"\n",
      "        },\n",
      "        \"cache/v1/20251001T000000Z/20251101T000000Z/uploads_by_country/stats.json\": {\n",
      "            \"sha256\": \"6f49579ca2877e8c90d313b8f3eca94332274a4e209afe90d37e689bfaf6a5e1\",\n",
      "            \"url\": \"https://github.com/m-lab/iqb/releases/download/v0.2.0/6f49579ca287__cache__v1__20251001T000000Z__20251101T000000Z__uploads_by_country__stats.json\"\n",
      "        }\n",
      "    },\n",
      "    \"v\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"03-research.dir/state/ghremote/manifest.json\") as fp:\n",
    "    print(json.dumps(json.load(fp), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7fd1a",
   "metadata": {},
   "source": [
    "Now let us create an entry that exists so we can exercise the remote cache.\n",
    "\n",
    "As before, we must create a *lazy* entry first. We reuse the same\n",
    "time window as the previous notebooks to keep the example consistent.\n",
    "\n",
    "The main difference with before is that an entry conceptually bundles\n",
    "multiple parquet files. However, just as before, the lazy design\n",
    "allows the researcher to only download what they actually need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed58be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iqb import IQBDatasetGranularity\n",
    "\n",
    "entry = cache.get_cache_entry(\n",
    "    granularity=IQBDatasetGranularity.COUNTRY,\n",
    "    start_date=\"2025-10-01\",  # start date is *inclusive*\n",
    "    end_date=\"2025-11-01\",  # end date is *exclusive*\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de61eb",
   "metadata": {},
   "source": [
    "OK, now that we have an entry, we can select specific\n",
    "subdata (e.g., for `mlab`) and sync it.\n",
    "\n",
    "The notebook example (in `./analysis`) shows how you can\n",
    "obtain data to compute the IQB score.\n",
    "\n",
    "Here, my intent is to show you, instead, how the low-level\n",
    "caching mechanism ties with the high-level read-only view\n",
    "so I am going to just sync a single parquet file.\n",
    "\n",
    "As in the previous example, we are filtering for the US and\n",
    "the same filtering knobs are available (it does not make\n",
    "sense here to filter for city, but we *could* do it). This\n",
    "call also triggers a sync under the hood, so this is the same\n",
    "pattern as before, wrapped into a higher-level interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04163ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = entry.mlab.read_download_data_frame(country_code=\"US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b0d94f",
   "metadata": {},
   "source": [
    "This is the same `pd.DataFrame` we have seen in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc7b414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['country_code', 'sample_count', 'download_p1', 'download_p5',\n",
       "       'download_p10', 'download_p25', 'download_p50', 'download_p75',\n",
       "       'download_p90', 'download_p95', 'download_p99', 'latency_p1',\n",
       "       'latency_p5', 'latency_p10', 'latency_p25', 'latency_p50',\n",
       "       'latency_p75', 'latency_p90', 'latency_p95', 'latency_p99',\n",
       "       'loss_p1', 'loss_p5', 'loss_p10', 'loss_p25', 'loss_p50',\n",
       "       'loss_p75', 'loss_p90', 'loss_p95', 'loss_p99'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.columns.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
